## Group Members Details: 

| MEMBER'S NAMES | MEMBER'S ID's |
| --------------- | --------------- |
| Mustufa Shahid | 64242 | 
| Maryam Naz | 64243 |
| Fizza Ishaq | 10481 | 
| Wajid Khan | 62584 | 
| Muhammad Saim | 64088 | 


NAIVE BAYES (LAPLACE SMOOTING)(WAJID KHAN):

this is the screenshot of kaggle accuracy.

![image](https://user-images.githubusercontent.com/64194854/169699843-2d55ca62-049c-4a38-aca7-5d71ef9ac416.png)

the accuracy of naive baye is 0.52313

HOW CAN I APROACH MY TASK?

1.First I  load the train.csv file from my system.

2.Afterthat I split the data into 60% and 40% into train and test files.

3.Then I train Naivebayes algorithm on the cleaned dataset.

4.And atlast I measued the accuracy and submit the file on Kaggle.

 k-Nearest Neighbors(MARYAM NAZ):
 
 ##KNN algorithm works:

find a distance between a query and all (variables) of data, select the particular number of examples (say K) nearest to the query, then decide 
the most frequent label if using for the classification based problems,  or
the averages the label if using for regression-based problems Therefore, the algorithm hugely depends upon the number of K, such that
Value of k â€“ bigger the value of k increases confidence in the prediction. 
Decisions may be suddenly change  if k has a very large value.

##Problem faced:

Does not work well with large dataset.

Does not work well with high dimensions.

Need feature scaling.

Sensitive to noisy data, missing values and outliers.

![knn by maryam](https://user-images.githubusercontent.com/74488616/169798177-62222b82-9645-4c78-aac2-d94c42d006ef.PNG)
